## Argo Events
HI

[Argo Events](https://argoproj.github.io/argo-events/) is an event-driven workflow automation framework for Kubernetes.

It helps you trigger K8s objects, Argo Workflows, Serverless workloads, etc. on events from a variety of sources like webhooks, S3, schedules, messaging queues, gcp pubsub, sns, sqs, etc.

### Installation

As well as all Argo projects, you can install Argo Events via:

- Plain manifest files
- Kustomization
- Helm Chart

In this course we will choose to install Argo Events via the chart.

```bash
# We need to add the repo chart
helm repo add argo https://argoproj.github.io/argo-helm

# We can now install the chart in a separate namespace
helm install argo-events argo/argo-events \
    -n argo-events \
    --create-namespace
```

Check if all the pods are up and running

```yaml
kubectl get pods -n argo-events
```

### Install some components

![Architecture](https://argoproj.github.io/argo-events/assets/argo-events-architecture.png "Architecture")

**Required resources**

A secret to authenticate the incomming requests

```bash
# Create a k8s secret with the secret to authenticate the request
kubectl create secret generic github-access-secret \
  --from-literal=secret=67fJfVV1MO7t8evRcOOit2SR7se98TbZEk2BnF14OYyAw \
  -n argo-events
```

The service account with permissions to create WorkFlows.

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: operate-workflow-sa
  namespace: argo-events
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: operate-workflow-role-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: admin
subjects:
  - kind: ServiceAccount
    name: operate-workflow-sa
    namespace: argo-events
```

**EventBus**

The eventbus is a resource that will process all the incomming events. It is a queue system that will dispatch all the events.

```yaml
apiVersion: argoproj.io/v1alpha1
kind: EventBus
metadata:
  name: default
  namespace: argo-events
spec:
  nats:
    native:
      replicas: 3
      auth: none
```

**EventSource**

Multiple systems generate multiple types of requests, specially the payload information varies depending on the system. Eg, github, Bitbucket and GitLab, they generate different data for the same type of event.

You can take a look a the multiple event sources that argo events supports https://github.com/argoproj/argo-events/tree/master/examples/event-sources

We will make use of the Github source

```yaml
apiVersion: argoproj.io/v1alpha1
kind: EventSource
metadata:
  name: github
  namespace: argo-events
spec:
  eventBusName: default
  template:
    container:
      env:
        - name: DEBUG_LOG
          value: "true"
  service:
    type: NodePort
    ports:
      - name: webhook
        port: 12000
        targetPort: 12000
  github:
    webhook:
      repositories:
        - owner: devopscompanynl
          names:
            - argowf-course
      webhook:
        endpoint: /push
        port: "12000"
        method: POST
      events:
        - "push"
      webhookSecret:
        # Name of the K8s secret that contains the hook secret
        name: github-access-secret
        # Key within the K8s secret whose corresponding value (must be base64 encoded) is hook secret
        key: secret
      insecure: true
      active: true
      contentType: json
```

**Sensor**

The sensor is the resource that helps us to retrieve information from the request of the source and defines the type of resource that will be generated by the incoming event.

In our case we want to trigger the `simple-pipeline` Workflow

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Sensor
metadata:
  name: p-argo-sn-dev-cli
  namespace: argo-events
spec:
  eventBusName: default
  template:
    # We need to create this service account
    serviceAccountName: operate-workflow-sa
  dependencies:
    - name: push-branch
      eventSourceName: github
      eventName: webhook
      filters:
        data:
          - path: body.X-GitHub-Event
            type: string
            value:
              - push
  triggers:
    - retryStrategy:
        steps: 1
      template:
        name: github-workflow-trigger
        k8s:
          operation: create
          source:
            resource:
              apiVersion: argoproj.io/v1alpha1
              kind: Workflow
              metadata:
                generateName: simple-pipeline-
                namespace: default
              spec:
                arguments:
                workflowTemplateRef:
                  name: simple-pipeline
```

This manifest will generate some pods with a webserver that will listen to incomming requests from the webhooks to generate workflow resources. Check if all the pods are up and running.

```bash
kubectl get pods -n argo-events
```

If they are running, we then expose the service as nodeport. The node will listen to the port 31200.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: github-eventsource-svc
  namespace: argo-events
spec:
  ports:
  - name: webhook
    port: 12000
    protocol: TCP
    targetPort: 12000
    nodePort: 31200
  selector:
    controller: eventsource-controller
    eventsource-name: github
    owner-name: github
  type: NodePort
```

## Configure a Github Webhook

1. Access to the your fork repository
2. Click on the *Settings* tab
3. Click on the option *Webhooks* on the left sidebar
4. Click on the button *Add webhook*
5. Fill in the following information:

  - Payload URL: http://IP_OF_YOUR_NODE:31200/push
  - Content type: application/json
  - Secret: 67fJfVV1MO7t8evRcOOit2SR7se98TbZEk2BnF14OYyAw

6. Click on add webhook

At this point, the webhook is properly configured.

Now it is time to push a commit to the repository to trigger this webhook. To do it you can edit one of the files of this repository by adding a new line, for example, and save it. This will trigger the webhook.

After that, navigate to the webhooks dashboard, you should be able to see a new Workflow `simple-pipeline` up and running.
